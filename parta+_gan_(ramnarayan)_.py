# -*- coding: utf-8 -*-
"""PartA+ GAN (Ramnarayan) .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UmIbe6w69S4_uMngoQqhJdBmXsbOLXyB
"""

from google.colab import drive
drive.mount('/content/drive')

"""In this we will make a output directory in which the output will be stored"""

# Specify the path where you want to create the directory
output_dir = '/content/drive/My Drive/my_output'

"""Get the number of persons who have more than one image"""

import os
import shutil
from collections import defaultdict
import random
import tarfile
from multiprocessing import Pool

# Define the path to your .tar dataset file
tar_file = "/content/drive/My Drive/lfw.tar"

# Create the output directory
output_dir = "/content/lfw"
os.makedirs(output_dir, exist_ok=True)

# Extract the .tar archive
with tarfile.open(tar_file, 'r') as tar:
    tar.extractall(output_dir)

# Define the ratio for splitting (e.g., 60% train, 20% validation, 20% test)
train_ratio = 0.6
validation_ratio = 0.2

for root, dirs, files in os.walk(output_dir):
    for file in files:
        person_name = os.path.basename(root)
        image_path = os.path.join(root, file)
        person_images[person_name].append(image_path)

# Get the number of persons with more than one image
persons_with_multiple_images = [person for person, images in person_images.items() if len(images)>=2]
num_persons_with_multiple_images = len(persons_with_multiple_images)
print(f"Number of persons with more than one image: {num_persons_with_multiple_images}")

import os

# Specify the path to the directory you want to get the size of
directory_path = "/content/drive/MyDrive/my_output/train"

def get_directory_size(path):
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(path):
        for filename in filenames:
            file_path = os.path.join(dirpath, filename)
            total_size += os.path.getsize(file_path)
    return total_size

directory_size_bytes = get_directory_size(directory_path)

# Convert the size to a human-readable format (e.g., megabytes)
def convert_bytes_to_megabytes(bytes):
    megabytes = bytes / (1024 * 1024)
    return megabytes

directory_size_megabytes = convert_bytes_to_megabytes(directory_size_bytes)

print(f"Size of the directory '{directory_path}': {directory_size_bytes} bytes ({directory_size_megabytes} MB)")

#Split images by person into train, validation, and test sets
for person, images in person_images.items():
    random.shuffle(images)
    num_images = len(images)
    num_train = int(train_ratio * num_images)
    num_val = int(validation_ratio * num_images)

    train_images = images[:num_train]
    val_images = images[num_train:num_train + num_val]
    test_images = images[num_train + num_val:]

    # Define output directories for train, validation, and test sets
    train_dir = os.path.join(output_dir, "train", person)
    val_dir = os.path.join(output_dir, "validation", person)
    test_dir = os.path.join(output_dir, "test", person)

    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(val_dir, exist_ok=True)
    os.makedirs(test_dir, exist_ok=True)

    # Copy images to the appropriate directories
    for image in train_images:
        dest_path = os.path.join(train_dir, os.path.basename(image))
        if image != dest_path:
            shutil.copy(image, dest_path)

    for image in val_images:
        dest_path = os.path.join(val_dir, os.path.basename(image))
        if image != dest_path:
            shutil.copy(image, dest_path)

    for image in test_images:
        dest_path = os.path.join(test_dir, os.path.basename(image))
        if image != dest_path:
            shutil.copy(image, dest_path)

import os

# Specify the path to the directory you want to get the size of
directory_path = "/content/drive/MyDrive/my_output/test"

def get_directory_size(path):
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(path):
        for filename in filenames:
            file_path = os.path.join(dirpath, filename)
            total_size += os.path.getsize(file_path)
    return total_size

directory_size_bytes = get_directory_size(directory_path)

# Convert the size to a human-readable format (e.g., megabytes)
def convert_bytes_to_megabytes(bytes):
    megabytes = bytes / (1024 * 1024)
    return megabytes

directory_size_megabytes = convert_bytes_to_megabytes(directory_size_bytes)

print(f"Size of the directory '{directory_path}': {directory_size_bytes} bytes ({directory_size_megabytes} MB)")

import os

# Specify the path to the directory you want to get the size of
directory_path = "/content/drive/MyDrive/my_output/validation"

def get_directory_size(path):
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(path):
        for filename in filenames:
            file_path = os.path.join(dirpath, filename)
            total_size += os.path.getsize(file_path)
    return total_size

directory_size_bytes = get_directory_size(directory_path)

# Convert the size to a human-readable format (e.g., megabytes)
def convert_bytes_to_megabytes(bytes):
    megabytes = bytes / (1024 * 1024)
    return megabytes

directory_size_megabytes = convert_bytes_to_megabytes(directory_size_bytes)

print(f"Size of the directory '{directory_path}': {directory_size_bytes} bytes ({directory_size_megabytes} MB)")

import os

# Specify the path to the directory you want to get the size of
directory_path = "/content/drive/MyDrive/my_output/lfw"

def get_directory_size(path):
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(path):
        for filename in filenames:
            file_path = os.path.join(dirpath, filename)
            total_size += os.path.getsize(file_path)
    return total_size

directory_size_bytes = get_directory_size(directory_path)

# Convert the size to a human-readable format (e.g., megabytes)
def convert_bytes_to_megabytes(bytes):
    megabytes = bytes / (1024 * 1024)
    return megabytes

directory_size_megabytes = convert_bytes_to_megabytes(directory_size_bytes)

print(f"Size of the directory '{directory_path}': {directory_size_bytes} bytes ({directory_size_megabytes} MB)")

import torch
import torchvision.models as models
import torch.nn as nn

# Load a pre-trained ResNet-50 model
pretrained_model = models.resnet50(pretrained=True)

custom_model = nn.Sequential(
    pretrained_model.conv1,
    pretrained_model.bn1,
    pretrained_model.relu,
    pretrained_model.maxpool,
    pretrained_model.layer1,
    pretrained_model.layer2,
    pretrained_model.layer3,
    pretrained_model.layer4,
    nn.AdaptiveAvgPool2d(1)  # Global Average Pooling
)

# Define your own fully connected layer(s) for classification
custom_model = nn.Sequential(
    custom_model,
    nn.Flatten(),
    nn.Linear(2048, 1000)  # Adjust num_classes to match your task
)

import cv2
import matplotlib.pyplot as plt

# Specify the path to your image
image_path = '/content/drive/MyDrive/my_output/lfw/AJ_Lamas/AJ_Lamas_0001.jpg'

# Load the image using OpenCV
image = cv2.imread(image_path)

# Check if the image was loaded successfully
if image is not None:
    # Convert from BGR to RGB color space (since OpenCV loads images in BGR format)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Display the image using matplotlib
    plt.imshow(image_rgb)
    plt.axis('off')  # Turn off the axis labels
    plt.show()
else:
    print("Failed to load the image.")

custom_model

import cv2

def preprocess_image(image_path, target_size):
    # Load the image
    image = cv2.imread(image_path)

    # Check if the image was loaded successfully
    if image is None:
        print(f"Failed to load image: {image_path}")
        return None

    # Resize the image while preserving the aspect ratio
    aspect_ratio = float(image.shape[1]) / image.shape[0]
    if aspect_ratio > 1:
        new_height = int(target_size / aspect_ratio)
        image = cv2.resize(image, (target_size, new_height))
    else:
        new_width = int(target_size * aspect_ratio)
        image = cv2.resize(image, (new_width, target_size))

    # Center-crop the image to the target size
    h, w = image.shape[:2]
    top = (h - target_size) // 2
    left = (w - target_size) // 2
    image = image[top:top + target_size, left:left + target_size]

    return image

# Example usage:
image_path = '/content/drive/MyDrive/my_output/lfw/AJ_Cook'
target_size = 512
preprocessed_image = preprocess_image(image_path, target_size)
if preprocessed_image is not None:
    # You can use the preprocessed_image for further processing or display
    pass  # Replace with your code

import cv2

# Specify the path to your image
image_path = '/content/drive/MyDrive/my_output/lfw/AJ_Lamas/AJ_Lamas_0001.jpg'

# Load the image using OpenCV
image = cv2.imread(image_path)

# Check if the image was loaded successfully
if image is not None:
    print("Image loaded successfully.")
else:
    print("Failed to load the image.")

image

import cv2
import matplotlib.pyplot as plt

# Specify the path to your image
image_path = '/content/drive/MyDrive/my_output/lfw/AJ_Lamas/AJ_Lamas_0001.jpg'

# Load the image using OpenCV
image = cv2.imread(image_path)

# Check if the image was loaded successfully
if image is not None:
    # Convert from BGR to RGB color space (since OpenCV loads images in BGR format)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Display the image using matplotlib
    plt.imshow(image_rgb)
    plt.axis('off')  # Turn off the axis labels
    plt.show()
else:
    print("Failed to load the image.")

"""Train a generative model for generating face images, using a GAN. The generator takes a Gaussian noise vector as input, and tries to output a face image, while the discriminator distinguishes between real and fake face images."""

pip install torch torchvision

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
import tarfile
import os

# Set random seed for reproducibility
torch.manual_seed(42)

# Define hyperparameters
batch_size = 64
latent_dim = 100
image_size = 64
num_epochs = 10000
lr = 0.0002

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Define paths
tar_file_path = '/content/drive/My Drive/lfw.tar'
extract_path = '/content/lfw'  # Destination directory

# Extract the dataset
with tarfile.open(tar_file_path, 'r') as tar:
    tar.extractall(path=extract_path)

# Define a custom dataset
transform = transforms.Compose([transforms.Resize((image_size, image_size)),
                                transforms.ToTensor()])
dataset = datasets.ImageFolder(root=extract_path, transform=transform)

# Create data loader
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Create the generator and discriminator and move them to the appropriate device
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Define the generator model
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, x):
        return self.main(x)

# Define the discriminator model
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(3, 128, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(512, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.main(x)

# Create the generator and discriminator
generator = Generator()
discriminator = Discriminator()

# Define loss function and optimizers
criterion = nn.BCELoss()
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

# Lists to store generated images
img_list = []

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Training loop
fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)  # For generating fixed samples


for epoch in range(num_epochs):
    for i, data in enumerate(data_loader, 0):
        real_images, _ = data
        batch_size = real_images.size(0)
        real_label = torch.full((batch_size,), 1.0)
        fake_label = torch.full((batch_size,), 0.0)

        # Train the discriminator
        optimizer_D.zero_grad()
        real_images = real_images.to(device)
        output = discriminator(real_images).view(-1)
        errD_real = criterion(output, real_label)
        errD_real.backward()

        noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)
        fake_images = generator(noise)
        output = discriminator(fake_images.detach()).view(-1)
        errD_fake = criterion(output, fake_label)
        errD_fake.backward()
        errD = errD_real + errD_fake
        optimizer_D.step()

        # Train the generator
        optimizer_G.zero_grad()
        output = discriminator(fake_images).view(-1)
        errG = criterion(output, real_label)
        errG.backward()
        optimizer_G.step()

        if i % 100 == 0:
            print(f'[{epoch}/{num_epochs}][{i}/{len(data_loader)}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f}')

    if (epoch % 100 == 0) or ((epoch == num_epochs - 1)):
        with torch.no_grad():
            fake = generator(fixed_noise).detach().cpu()
            img_list.append(torchvision.utils.make_grid(fake, padding=2, normalize=True))

# Save the trained model
torch.save(generator.state_dict(), '/content/drive/My Drive/generator.pth')
torch.save(discriminator.state_dict(), '/content/drive/My Drive/discriminator.pth')

# Save generated images
for i in range(len(img_list)):
    fig = plt.figure(figsize=(8, 8))
    plt.axis("off")
    plt.imshow(np.transpose(img_list[i], (1, 2, 0)))
    plt.savefig(f"/content/drive/My Drive/gan_generated_image_epoch_{i}.png")
    plt.close()

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
import tarfile
import os

# Set the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Set random seed for reproducibility
torch.manual_seed(42)

# Define hyperparameters
batch_size = 64
latent_dim = 100
image_size = 64
num_epochs = 10000
lr = 0.0002

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Define paths
tar_file_path = '/content/drive/My Drive/lfw.tar'
extract_path = '/content/lfw'  # Destination directory

# Extract the dataset
with tarfile.open(tar_file_path, 'r') as tar:
    tar.extractall(path=extract_path)

# Define a custom dataset
transform = transforms.Compose([transforms.Resize((image_size, image_size)),
                                transforms.ToTensor()])
dataset = datasets.ImageFolder(root=extract_path, transform=transform)

# Create data loader
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Define the generator model
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, x):
        return self.main(x)

# Define the discriminator model
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(3, 128, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(512, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.main(x)

# Create the generator and discriminator and move them to the appropriate device
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Define loss function and optimizers
criterion = nn.BCELoss()
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

# Lists to store generated images
img_list = []

# Training loop# ...

# Training loop
fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)  # For generating fixed samples

for epoch in range(num_epochs):
    for i, data in enumerate(data_loader, 0):
        real_images, _ = data
        batch_size = real_images.size(0)
        real_label = torch.full((batch_size, 1, 1, 1), 1.0, device=device)

        # Ensure that fake_label matches the size of the output from the generator
        fake_label = torch.full((batch_size, 1, 5, 5), 0.0, device=device)

        # Train the discriminator
        optimizer_D.zero_grad()
        real_images = real_images.to(device)
        output = discriminator(real_images)
        errD_real = criterion(output, real_label)
        errD_real.backward()

        noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)
        fake_images = generator(noise)
        output = discriminator(fake_images.detach())

        # Ensure that fake_label matches the size of the output from the generator
        fake_label = torch.full(output.shape, 0.0, device=device)

        errD_fake = criterion(output, fake_label)
        errD_fake.backward()
        errD = errD_real + errD_fake
        optimizer_D.step()

        # Train the generator
        optimizer_G.zero_grad()
        output = discriminator(fake_images)

        # Ensure that real_label matches the size of the output from the generator
        real_label = torch.full(output.shape, 1.0, device=device)

        errG = criterion(output, real_label)
        errG.backward()
        optimizer_G.step()

        if i % 100 == 0:
            print(f'[{epoch}/{num_epochs}][{i}/{len(data_loader)}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f}')



    if (epoch % 100 == 0) or ((epoch == num_epochs - 1)):
        with torch.no_grad():
            fake = generator(fixed_noise).detach().cpu()
            img_list.append(torchvision.utils.make_grid(fake, padding=2, normalize=True))

# Save the trained model
torch.save(generator.state_dict(), '/content/drive/My Drive/generator.pth')
torch.save(discriminator.state_dict(), '/content/drive/My Drive/discriminator.pth')

# Save generated images
for i in range(len(img_list)):
    fig = plt.figure(figsize=(8, 8))
    plt.axis("off")
    plt.imshow(np.transpose(img_list[i], (1, 2, 0)))
    plt.savefig(f"/content/drive/My Drive/gan_generated_image_epoch_{i}.png")
    plt.close()